{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取tf.record文件，包括解码、reshape、shuffle_batch、归一化处理\n",
    "def dataset(data_type='train', batch_size=10):\n",
    "    # 创建队列保护输入文件列表\n",
    "    filename_queue = tf.train.string_input_producer(['data/' + data_type + '.tfrecords'])  \n",
    "    # 读取并解析一个tfrecord\n",
    "    reader = tf.TFRecordReader()  \n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       })\n",
    "    image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    # reshape\n",
    "    image = tf.reshape(image, [1152])\n",
    "    image = tf.cast(image, tf.float32)/255\n",
    "    label = tf.cast(features['label'], tf.int64)\n",
    "    img_batch, l_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        capacity=500,\n",
    "        min_after_dequeue=0)\n",
    "    return img_batch, l_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二次数据处理：标签转换为one-hot类型，图片和标签转成ndarray\n",
    "def dataset2(data_type, num):\n",
    "    print(\"training...\")\n",
    "    img_b = np.empty([num, 1152])\n",
    "    l_b = np.empty([num, 34])\n",
    "    img, l = dataset(data_type, num)\n",
    "    with tf.Session() as sess: \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        coord=tf.train.Coordinator()\n",
    "        threads= tf.train.start_queue_runners(coord=coord)\n",
    "        img, l = sess.run([img, l])\n",
    "        for i in range(num):\n",
    "            img_b[i] = img[i]\n",
    "            l_b[i] = tf.one_hot(l[i], depth=34).eval()\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    print(\"done\")\n",
    "    return img_b, l_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
